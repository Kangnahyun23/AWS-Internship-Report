[
{
	"uri": "//localhost:1313/",
	"title": "Internship Report",
	"tags": [],
	"description": "",
	"content": "Internship Report Student Information: Full Name: Bui Nguyen Tan Khang\nPhone Number: 038 391 2577\nEmail: tankhang6a6@gmail.com\nUniversity: FPT University HCMC\nMajor: Software Engineering\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 08/09/2025 to 00/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "
},
{
	"uri": "//localhost:1313/3-blogstranslated/3.1-blog1/",
	"title": "Join AWS at PASS Data Community Summit 2024",
	"tags": [],
	"description": "",
	"content": "Author: Frank Wang\nDate: 02 OCT 2024\nTopic: Amazon Aurora, Amazon EC2, Amazon Q, Amazon RDS\u0026hellip;\n(This is a placeholder for the English content. Please refer to the Vietnamese version for the full translated text.)\nAWS is excited to announce our participation as a Platinum sponsor at the PASS Data Community Summit 2024, continuing our commitment to empowering organizations with our data and AI services. Our mission is to help businesses migrate, optimize, and modernize Microsoft SQL Server workloads, while accelerating innovation, delivering unparalleled reliability, security, and cost efficiency — all on the world\u0026rsquo;s most comprehensive and widely adopted cloud platform.\n"
},
{
	"uri": "//localhost:1313/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nSummary Report: “GenAI-powered App-DB Modernization workshop” Event Objectives Share best practices in modern application design Introduce Domain-Driven Design (DDD) and event-driven architecture Provide guidance on selecting the right compute services Present AI tools to support the development lifecycle Speakers Jignesh Shah – Director, Open Source Databases Erica Liu – Sr. GTM Specialist, AppMod Fabrianne Effendi – Assc. Specialist SA, Serverless Amazon Web Services Key Highlights Identifying the drawbacks of legacy application architecture Long product release cycles → Lost revenue/missed opportunities Inefficient operations → Reduced productivity, higher costs Non-compliance with security regulations → Security breaches, loss of reputation Transitioning to modern application architecture – Microservices Migrating to a modular system — each function is an independent service communicating via events, built on three core pillars:\nQueue Management: Handle asynchronous tasks Caching Strategy: Optimize performance Message Handling: Flexible inter-service communication Domain-Driven Design (DDD) Four-step method: Identify domain events → arrange timeline → identify actors → define bounded contexts Bookstore case study: Demonstrates real-world DDD application Context mapping: 7 patterns for integrating bounded contexts Event-Driven Architecture 3 integration patterns: Publish/Subscribe, Point-to-point, Streaming Benefits: Loose coupling, scalability, resilience Sync vs async comparison: Understanding the trade-offs Compute Evolution Shared Responsibility Model: EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria for appropriate choice Amazon Q Developer SDLC automation: From planning to maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Key Takeaways Design Mindset Business-first approach: Always start from the business domain, not the technology Ubiquitous language: Importance of a shared vocabulary between business and tech teams Bounded contexts: Identifying and managing complexity in large systems Technical Architecture Event storming technique: Practical method for modeling business processes Use event-driven communication instead of synchronous calls Integration patterns: When to use sync, async, pub/sub, streaming Compute spectrum: Criteria for choosing between VM, containers, and serverless Modernization Strategy Phased approach: No rushing — follow a clear roadmap 7Rs framework: Multiple modernization paths depending on the application ROI measurement: Cost reduction + business agility Applying to Work Apply DDD to current projects: Event storming sessions with business teams Refactor microservices: Use bounded contexts to define service boundaries Implement event-driven patterns: Replace some sync calls with async messaging Adopt serverless: Pilot AWS Lambda for suitable use cases Try Amazon Q Developer: Integrate into the dev workflow to boost productivity Event Experience Attending the “GenAI-powered App-DB Modernization” workshop was extremely valuable, giving me a comprehensive view of modernizing applications and databases using advanced methods and tools. Key experiences included:\nLearning from highly skilled speakers Experts from AWS and major tech organizations shared best practices in modern application design. Through real-world case studies, I gained a deeper understanding of applying DDD and Event-Driven Architecture to large projects. Hands-on technical exposure Participating in event storming sessions helped me visualize how to model business processes into domain events. Learned how to split microservices and define bounded contexts to manage large-system complexity. Understood trade-offs between synchronous and asynchronous communication and integration patterns like pub/sub, point-to-point, streaming. Leveraging modern tools Explored Amazon Q Developer, an AI tool for SDLC support from planning to maintenance. Learned to automate code transformation and pilot serverless with AWS Lambda to improve productivity. Networking and discussions The workshop offered opportunities to exchange ideas with experts, peers, and business teams, enhancing the ubiquitous language between business and tech. Real-world examples reinforced the importance of the business-first approach rather than focusing solely on technology. Lessons learned Applying DDD and event-driven patterns reduces coupling while improving scalability and resilience. Modernization requires a phased approach with ROI measurement; rushing the process can be risky. AI tools like Amazon Q Developer can significantly boost productivity when integrated into the current workflow. Some event photos Add your event photos here\nOverall, the event not only provided technical knowledge but also helped me reshape my thinking about application design, system modernization, and cross-team collaboration.\n"
},
{
	"uri": "//localhost:1313/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nSummary Report: “GenAI-powered App-DB Modernization workshop” Event Objectives Share best practices in modern application design Introduce Domain-Driven Design (DDD) and event-driven architecture Provide guidance on selecting the right compute services Present AI tools to support the development lifecycle Speakers Jignesh Shah – Director, Open Source Databases Erica Liu – Sr. GTM Specialist, AppMod Fabrianne Effendi – Assc. Specialist SA, Serverless Amazon Web Services Key Highlights Identifying the drawbacks of legacy application architecture Long product release cycles → Lost revenue/missed opportunities Inefficient operations → Reduced productivity, higher costs Non-compliance with security regulations → Security breaches, loss of reputation Transitioning to modern application architecture – Microservices Migrating to a modular system — each function is an independent service communicating via events, built on three core pillars:\nQueue Management: Handle asynchronous tasks Caching Strategy: Optimize performance Message Handling: Flexible inter-service communication Domain-Driven Design (DDD) Four-step method: Identify domain events → arrange timeline → identify actors → define bounded contexts Bookstore case study: Demonstrates real-world DDD application Context mapping: 7 patterns for integrating bounded contexts Event-Driven Architecture 3 integration patterns: Publish/Subscribe, Point-to-point, Streaming Benefits: Loose coupling, scalability, resilience Sync vs async comparison: Understanding the trade-offs Compute Evolution Shared Responsibility Model: EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria for appropriate choice Amazon Q Developer SDLC automation: From planning to maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Key Takeaways Design Mindset Business-first approach: Always start from the business domain, not the technology Ubiquitous language: Importance of a shared vocabulary between business and tech teams Bounded contexts: Identifying and managing complexity in large systems Technical Architecture Event storming technique: Practical method for modeling business processes Use event-driven communication instead of synchronous calls Integration patterns: When to use sync, async, pub/sub, streaming Compute spectrum: Criteria for choosing between VM, containers, and serverless Modernization Strategy Phased approach: No rushing — follow a clear roadmap 7Rs framework: Multiple modernization paths depending on the application ROI measurement: Cost reduction + business agility Applying to Work Apply DDD to current projects: Event storming sessions with business teams Refactor microservices: Use bounded contexts to define service boundaries Implement event-driven patterns: Replace some sync calls with async messaging Adopt serverless: Pilot AWS Lambda for suitable use cases Try Amazon Q Developer: Integrate into the dev workflow to boost productivity Event Experience Attending the “GenAI-powered App-DB Modernization” workshop was extremely valuable, giving me a comprehensive view of modernizing applications and databases using advanced methods and tools. Key experiences included:\nLearning from highly skilled speakers Experts from AWS and major tech organizations shared best practices in modern application design. Through real-world case studies, I gained a deeper understanding of applying DDD and Event-Driven Architecture to large projects. Hands-on technical exposure Participating in event storming sessions helped me visualize how to model business processes into domain events. Learned how to split microservices and define bounded contexts to manage large-system complexity. Understood trade-offs between synchronous and asynchronous communication and integration patterns like pub/sub, point-to-point, streaming. Leveraging modern tools Explored Amazon Q Developer, an AI tool for SDLC support from planning to maintenance. Learned to automate code transformation and pilot serverless with AWS Lambda to improve productivity. Networking and discussions The workshop offered opportunities to exchange ideas with experts, peers, and business teams, enhancing the ubiquitous language between business and tech. Real-world examples reinforced the importance of the business-first approach rather than focusing solely on technology. Lessons learned Applying DDD and event-driven patterns reduces coupling while improving scalability and resilience. Modernization requires a phased approach with ROI measurement; rushing the process can be risky. AI tools like Amazon Q Developer can significantly boost productivity when integrated into the current workflow. Some event photos Add your event photos here\nOverall, the event not only provided technical knowledge but also helped me reshape my thinking about application design, system modernization, and cross-team collaboration.\n"
},
{
	"uri": "//localhost:1313/5-workshop/5.1-preparation/",
	"title": "Setting up Development Environment",
	"tags": [],
	"description": "",
	"content": "1. Prerequisites To develop modern web applications, you need the following standard tools:\nNode.js (LTS Version): Runtime environment for JavaScript/TypeScript. Git: Distributed version control system. IDE: Visual Studio Code (recommended). Recommended VS Code Extensions:\nESLint \u0026amp; Prettier: Automate formatting and linting. Tailwind CSS IntelliSense: Rapid Tailwind class suggestions. ES7+ React/Redux/React-Native snippets: Code faster with shortcuts. 2. Initialize Next.js Project We will use Next.js - the most popular React Framework today.\nRun initialization command:\nnpx create-next-app@latest my-serverless-app Detailed Configuration:\nTypeScript: Yes (Type safety) Tailwind CSS: Yes (Rapid styling) ESLint: Yes (Linting) App Router: Yes (Latest routing architecture) Import Alias: @/ (Cleaner imports) 3. Standard Project Structure A scientific folder structure helps with future maintenance:\nsrc/app: Contains Pages and Layouts (App Router). src/components: Contains reusable UI Components (Button, Card\u0026hellip;). src/hooks: Contains Custom Hooks (useAuth, useChat\u0026hellip;). src/lib: Contains utility functions and configurations (AWS config). 4. Configure tsconfig.json (Best Practices) To ensure strict TypeScript coding, update tsconfig.json:\n{ \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;es5\u0026#34;, \u0026#34;lib\u0026#34;: [\u0026#34;dom\u0026#34;, \u0026#34;dom.iterable\u0026#34;, \u0026#34;esnext\u0026#34;], \u0026#34;allowJs\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;strict\u0026#34;: true, // Important: Enable strict mode \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true, \u0026#34;noEmit\u0026#34;: true, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;module\u0026#34;: \u0026#34;esnext\u0026#34;, \u0026#34;moduleResolution\u0026#34;: \u0026#34;node\u0026#34;, \u0026#34;resolveJsonModule\u0026#34;: true, \u0026#34;isolatedModules\u0026#34;: true, \u0026#34;jsx\u0026#34;: \u0026#34;preserve\u0026#34;, \u0026#34;incremental\u0026#34;: true, \u0026#34;plugins\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;next\u0026#34; } ], \u0026#34;paths\u0026#34;: { \u0026#34;@/*\u0026#34;: [\u0026#34;./src/*\u0026#34;] } }, \u0026#34;include\u0026#34;: [\u0026#34;next-env.d.ts\u0026#34;, \u0026#34;**/*.ts\u0026#34;, \u0026#34;**/*.tsx\u0026#34;, \u0026#34;.next/types/**/*.ts\u0026#34;], \u0026#34;exclude\u0026#34;: [\u0026#34;node_modules\u0026#34;] } 5. Install UI Libraries cd my-serverless-app npm install framer-motion lucide-react clsx tailwind-merge 6. Configure TailwindCSS Set up CSS Variables in tailwind.config.ts to ensure Design System consistency.\n// tailwind.config.ts import type { Config } from \u0026#34;tailwindcss\u0026#34;; const config: Config = { content: [ \u0026#34;./src/pages/**/*.{js,ts,jsx,tsx,mdx}\u0026#34;, \u0026#34;./src/components/**/*.{js,ts,jsx,tsx,mdx}\u0026#34;, \u0026#34;./src/app/**/*.{js,ts,jsx,tsx,mdx}\u0026#34;, ], theme: { extend: { colors: { primary: \u0026#34;#432c7a\u0026#34;, // Primary color secondary: \u0026#34;#764ba2\u0026#34;, accent: \u0026#34;#ffd700\u0026#34;, background: \u0026#34;#1a0b2e\u0026#34;, // Dark background }, backgroundImage: { \u0026#34;gradient-radial\u0026#34;: \u0026#34;radial-gradient(var(--tw-gradient-stops))\u0026#34;, }, }, }, plugins: [], }; export default config; My Experience Why TypeScript? When I first started, I found TypeScript annoying because of all the red errors. But as the project grew, those errors saved me from dozens of silly bugs (like typos, wrong data types). Advice: Enable strict: true from the start. \u0026ldquo;Short term pain, long term gain\u0026rdquo;!\nVerification \u0026amp; Testing To ensure the environment is ready, perform the following checks:\nTest Case 1: Check Node.js Version Open terminal and run:\nnode -v Expected Result: v18.x.x or higher (LTS).\nTest Case 2: Run Development Server\nnpm run dev Expected Result: Terminal shows:\nready - started server on 0.0.0.0:3000, url: http://localhost:3000\revent - compiled client and server successfully in 1234 ms (150 modules) Access browser and see the spinning Next.js logo!\n"
},
{
	"uri": "//localhost:1313/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 1 Objectives: Get acquainted with company culture, TEEJ team members, mentors, and FCJ participants. Initialize and set up a standard AWS account environment. Understand and configure Cost Management. Master Identity and Access Management (IAM) concepts. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Onboarding \u0026amp; Networking:\n+ Meet and greet TEEJ team and Mentors\n+ Network with FCJ program participants\n- Create AWS Account:\n+ Sign up for Free Tier account\n+ Verify payment info and phone number\n+ Enable MFA for Root account 08/09/2025 08/09/2025 Cloud Journey - Create Account 3 - Cost Management with AWS Budgets:\n+ Create a Budget for cost alerts\n+ Set up alert thresholds via email\n- Learn about AWS Support Plans 09/09/2025 09/09/2025 Cloud Journey - AWS Budgets 4 - Access Management with IAM (Part 1):\n+ Create IAM User for Administrator\n+ Create IAM Group and attach policies\n+ Set up secure Password Policy 10/09/2025 10/09/2025 Cloud Journey - IAM 5 - Access Management with IAM (Part 2):\n+ Configure MFA for IAM User\n+ Practice logging in and Switching Roles\n+ Learn about IAM Policy Structure (JSON) 11/09/2025 11/09/2025 Cloud Journey - IAM 6 - Week 1 Review:\n+ Review security settings\n+ Check Billing Dashboard to ensure no unexpected costs 12/09/2025 12/09/2025 Self-review Week 1 Achievements: Successfully integrated into the new environment, connected with TEEJ team, Mentors, and FCJ peers. Secured AWS account with MFA enabled for Root User. Successfully set up budget alerts to avoid \u0026ldquo;bill shock\u0026rdquo;. Understood the Shared Responsibility Model. Managed Users, Groups, and Permissions with IAM. "
},
{
	"uri": "//localhost:1313/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "On this page, you will find the complete Worklog recording my internship journey at the company. The internship program lasted for 12 weeks, ranging from getting familiar with the new environment and basic services to deploying complex systems and application modernization.\nHere is a summary of the weekly contents:\nWeek 1: Onboarding, Account, IAM \u0026amp; Cost Management\nWeek 2: Virtual Network VPC, EC2 Servers \u0026amp; IAM Roles\nWeek 3: Cloud9 Environment \u0026amp; Static Web Hosting with S3\nWeek 4: Simplified VPS with Lightsail \u0026amp; Containerization\nWeek 5: High Availability \u0026amp; Auto Scaling with CloudWatch\nWeek 6: NoSQL Database (DynamoDB) \u0026amp; Caching (ElastiCache)\nWeek 7: Advanced Networking (VPC Peering, VPN) \u0026amp; CDN (CloudFront)\nWeek 8: Operational Optimization (Lambda, Systems Manager, CloudFormation)\nWeek 9: App Modernization: Serverless Basic (Lambda, API Gateway)\nWeek 10: Serverless Fullstack: Cognito, SQS, SNS\nWeek 11: DevOps: CI/CD, Monitoring \u0026amp; AppSync\nWeek 12: Review, Final Report \u0026amp; Defense Preparation\n"
},
{
	"uri": "//localhost:1313/3-blogstranslated/3.2-blog2/",
	"title": "AWS .NET Distributed Cache Provider for Amazon DynamoDB now Generally Available",
	"tags": [],
	"description": "",
	"content": "Author: Garrett Beatty\nDate: 03 JUL 2025\nTopic: .NET, AWS SDK for .NET, Developer Tools\u0026hellip;\n(This is a placeholder for the English content. Please refer to the Vietnamese version for the full translated text.)\nToday, we are excited to announce the general availability of the AWS .NET Distributed Cache Provider for Amazon DynamoDB. This is a seamless, serverless caching solution that enables .NET developers to effectively manage their caching needs on distributed systems.\n"
},
{
	"uri": "//localhost:1313/5-workshop/5.2-ui-implementation/",
	"title": "Building Modern User Interface",
	"tags": [],
	"description": "",
	"content": "1. Layout Design (Responsive \u0026amp; Glassmorphism) Our goal is to create a mystical, \u0026ldquo;AI Sorcerer\u0026rdquo; interface like the Mockup below:\nUse CSS Grid and Flexbox from Tailwind to create flexible layouts.\n// src/app/layout.tsx export default function RootLayout({ children }: { children: React.ReactNode }) { return ( \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;body className=\u0026#34;bg-background text-white min-h-screen bg-[url(\u0026#39;/bg-stars.png\u0026#39;)] bg-cover\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;absolute inset-0 bg-black/50\u0026#34; /\u0026gt; {/* Overlay */} \u0026lt;main className=\u0026#34;relative z-10 container mx-auto px-4 py-8 grid grid-cols-1 lg:grid-cols-12 gap-6\u0026#34;\u0026gt; {/* Sidebar takes 3 cols on Desktop */} \u0026lt;aside className=\u0026#34;lg:col-span-3 hidden lg:block\u0026#34;\u0026gt; {/* Sidebar Content */} \u0026lt;/aside\u0026gt; {/* Main Content takes 9 cols */} \u0026lt;section className=\u0026#34;lg:col-span-9\u0026#34;\u0026gt; {children} \u0026lt;/section\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ) } 2. Component: Horoscope Widget Create a Widget displaying daily horoscope with Glassmorphism effect.\n// src/components/HoroscopeWidget.tsx import { Star } from \u0026#39;lucide-react\u0026#39;; export default function HoroscopeWidget({ sign, prediction }: { sign: string, prediction: string }) { return ( \u0026lt;div className=\u0026#34;p-6 rounded-2xl bg-white/10 backdrop-blur-lg border border-white/20 hover:bg-white/20 transition-all duration-300 group\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;flex items-center gap-3 mb-4\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;p-3 rounded-full bg-accent/20 text-accent group-hover:scale-110 transition-transform\u0026#34;\u0026gt; \u0026lt;Star size={24} /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h3 className=\u0026#34;text-xl font-bold\u0026#34;\u0026gt;{sign}\u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;p className=\u0026#34;text-gray-300 leading-relaxed\u0026#34;\u0026gt;{prediction}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ); } 3. Component: Chat Interface Build chat interface with auto-scroll and dynamic message styling.\n// src/components/ChatBox.tsx import { useEffect, useRef } from \u0026#39;react\u0026#39;; import { clsx } from \u0026#39;clsx\u0026#39;; export default function ChatBox({ messages }: { messages: Message[] }) { const bottomRef = useRef\u0026lt;HTMLDivElement\u0026gt;(null); // Auto-scroll to bottom useEffect(() =\u0026gt; { bottomRef.current?.scrollIntoView({ behavior: \u0026#39;smooth\u0026#39; }); }, [messages]); return ( \u0026lt;div className=\u0026#34;flex flex-col h-[600px] bg-white/5 rounded-xl border border-white/10 overflow-hidden\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;flex-1 overflow-y-auto p-4 space-y-4\u0026#34;\u0026gt; {messages.map((msg, idx) =\u0026gt; ( \u0026lt;div key={idx} className={clsx( \u0026#34;max-w-[80%] p-3 rounded-lg\u0026#34;, msg.role === \u0026#39;user\u0026#39; ? \u0026#34;bg-primary self-end ml-auto\u0026#34; : \u0026#34;bg-white/10 self-start mr-auto\u0026#34; )}\u0026gt; {msg.content} \u0026lt;/div\u0026gt; ))} \u0026lt;div ref={bottomRef} /\u0026gt; \u0026lt;/div\u0026gt; {/* Input Area */} \u0026lt;/div\u0026gt; ); } 4. Animation with Framer Motion Add smooth entrance effects for UI elements.\nimport { motion } from \u0026#39;framer-motion\u0026#39;; const fadeIn = { hidden: { opacity: 0, y: 20 }, visible: { opacity: 1, y: 0 } }; \u0026lt;motion.div initial=\u0026#34;hidden\u0026#34; animate=\u0026#34;visible\u0026#34; variants={fadeIn} transition={{ duration: 0.5 }} \u0026gt; \u0026lt;HoroscopeWidget sign=\u0026#34;Leo\u0026#34; prediction=\u0026#34;Today is your lucky day!\u0026#34; /\u0026gt; \u0026lt;/motion.div\u0026gt; My Experience Mobile-First or Desktop-First? Initially, I designed for Desktop first, and when I opened it on mobile, the layout was broken. Lesson: Always use classes like hidden lg:block or grid-cols-1 lg:grid-cols-12 to prioritize Mobile layout first (default), then override for larger screens. TailwindCSS makes this incredibly easy!\nVerification \u0026amp; Testing Test Case 1: Responsive Design\nOpen browser on Desktop: See Sidebar on left, Chatbox on right. Press F12, switch to Mobile mode (iPhone 12/14). Expected Result: Sidebar hidden, Chatbox takes full width. Test Case 2: Hover Effects\nHover over HoroscopeWidget. Expected Result: Background brightens (bg-white/20), star icon scales up slightly (scale-110). "
},
{
	"uri": "//localhost:1313/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": " ⚠️ Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nIn this section, you need to summarize the contents of the workshop that you plan to conduct.\nIoT Weather Platform for Lab Research A Unified AWS Serverless Solution for Real-Time Weather Monitoring 1. Executive Summary The IoT Weather Platform is designed for the ITea Lab team in Ho Chi Minh City to enhance weather data collection and analysis. It supports up to 5 weather stations, with potential scalability to 10-15, utilizing Raspberry Pi edge devices with ESP32 sensors to transmit data via MQTT. The platform leverages AWS Serverless services to deliver real-time monitoring, predictive analytics, and cost efficiency, with access restricted to 5 lab members via Amazon Cognito.\n2. Problem Statement What’s the Problem? Current weather stations require manual data collection, becoming unmanageable with multiple units. There is no centralized system for real-time data or analytics, and third-party platforms are costly and overly complex.\nThe Solution The platform uses AWS IoT Core to ingest MQTT data, AWS Lambda and API Gateway for processing, Amazon S3 for storage (including a data lake), and AWS Glue Crawlers and ETL jobs to extract, transform, and load data from the S3 data lake to another S3 bucket for analysis. AWS Amplify with Next.js provides the web interface, and Amazon Cognito ensures secure access. Similar to Thingsboard and CoreIoT, users can register new devices and manage connections, though this platform operates on a smaller scale and is designed for private use. Key features include real-time dashboards, trend analysis, and low operational costs.\nBenefits and Return on Investment The solution establishes a foundational resource for lab members to develop a larger IoT platform, serving as a study resource, and provides a data foundation for AI enthusiasts for model training or analysis. It reduces manual reporting for each station via a centralized platform, simplifying management and maintenance, and improves data reliability. Monthly costs are $0.66 USD per the AWS Pricing Calculator, with a 12-month total of $7.92 USD. All IoT equipment costs are covered by the existing weather station setup, eliminating additional development expenses. The break-even period of 6-12 months is achieved through significant time savings from reduced manual work.\n3. Solution Architecture The platform employs a serverless AWS architecture to manage data from 5 Raspberry Pi-based stations, scalable to 15. Data is ingested via AWS IoT Core, stored in an S3 data lake, and processed by AWS Glue Crawlers and ETL jobs to transform and load it into another S3 bucket for analysis. Lambda and API Gateway handle additional processing, while Amplify with Next.js hosts the dashboard, secured by Cognito. The architecture is detailed below:\nAWS Services Used AWS IoT Core: Ingests MQTT data from 5 stations, scalable to 15. AWS Lambda: Processes data and triggers Glue jobs (two functions). Amazon API Gateway: Facilitates web app communication. Amazon S3: Stores raw data in a data lake and processed outputs (two buckets). AWS Glue: Crawlers catalog data, and ETL jobs transform and load it. AWS Amplify: Hosts the Next.js web interface. Amazon Cognito: Secures access for lab users. Component Design Edge Devices: Raspberry Pi collects and filters sensor data, sending it to IoT Core. Data Ingestion: AWS IoT Core receives MQTT messages from the edge devices. Data Storage: Raw data is stored in an S3 data lake; processed data is stored in another S3 bucket. Data Processing: AWS Glue Crawlers catalog the data, and ETL jobs transform it for analysis. Web Interface: AWS Amplify hosts a Next.js app for real-time dashboards and analytics. User Management: Amazon Cognito manages user access, allowing up to 5 active accounts. 4. Technical Implementation Implementation Phases This project has two parts—setting up weather edge stations and building the weather platform—each following 4 phases:\nBuild Theory and Draw Architecture: Research Raspberry Pi setup with ESP32 sensors and design the AWS serverless architecture (1 month pre-internship) Calculate Price and Check Practicality: Use AWS Pricing Calculator to estimate costs and adjust if needed (Month 1). Fix Architecture for Cost or Solution Fit: Tweak the design (e.g., optimize Lambda with Next.js) to stay cost-effective and usable (Month 2). Develop, Test, and Deploy: Code the Raspberry Pi setup, AWS services with CDK/SDK, and Next.js app, then test and release to production (Months 2-3). Technical Requirements\nWeather Edge Station: Sensors (temperature, humidity, rainfall, wind speed), a microcontroller (ESP32), and a Raspberry Pi as the edge device. Raspberry Pi runs Raspbian, handles Docker for filtering, and sends 1 MB/day per station via MQTT over Wi-Fi. Weather Platform: Practical knowledge of AWS Amplify (hosting Next.js), Lambda (minimal use due to Next.js), AWS Glue (ETL), S3 (two buckets), IoT Core (gateway and rules), and Cognito (5 users). Use AWS CDK/SDK to code interactions (e.g., IoT Core rules to S3). Next.js reduces Lambda workload for the fullstack web app. 5. Timeline \u0026amp; Milestones Project Timeline\nPre-Internship (Month 0): 1 month for planning and old station review. Internship (Months 1-3): 3 months. Month 1: Study AWS and upgrade hardware. Month 2: Design and adjust architecture. Month 3: Implement, test, and launch. Post-Launch: Up to 1 year for research. 6. Budget Estimation You can find the budget estimation on the AWS Pricing Calculator.\nOr you can download the Budget Estimation File.\nInfrastructure Costs AWS Services: AWS Lambda: $0.00/month (1,000 requests, 512 MB storage). S3 Standard: $0.15/month (6 GB, 2,100 requests, 1 GB scanned). Data Transfer: $0.02/month (1 GB inbound, 1 GB outbound). AWS Amplify: $0.35/month (256 MB, 500 ms requests). Amazon API Gateway: $0.01/month (2,000 requests). AWS Glue ETL Jobs: $0.02/month (2 DPUs). AWS Glue Crawlers: $0.07/month (1 crawler). MQTT (IoT Core): $0.08/month (5 devices, 45,000 messages). Total: $0.7/month, $8.40/12 months\nHardware: $265 one-time (Raspberry Pi 5 and sensors). 7. Risk Assessment Risk Matrix Network Outages: Medium impact, medium probability. Sensor Failures: High impact, low probability. Cost Overruns: Medium impact, low probability. Mitigation Strategies Network: Local storage on Raspberry Pi with Docker. Sensors: Regular checks and spares. Cost: AWS budget alerts and optimization. Contingency Plans Revert to manual methods if AWS fails. Use CloudFormation for cost-related rollbacks. 8. Expected Outcomes Technical Improvements: Real-time data and analytics replace manual processes.\nScalable to 10-15 stations.\nLong-term Value 1-year data foundation for AI research.\nReusable for future projects.\n"
},
{
	"uri": "//localhost:1313/1-worklog/1.2-week2/",
	"title": "Week 2 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 2 Objectives: Build basic virtual network infrastructure (VPC). Launch and manage virtual servers (EC2). Understand application permission mechanisms (IAM Roles). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Basic Networking (VPC):\n+ Create VPC, Subnets (Public/Private)\n+ Configure Internet Gateway and Route Tables 15/09/2025 15/09/2025 Cloud Journey - VPC 3 - Virtual Servers EC2 (Part 1):\n+ Learn about Instance Families/Types\n+ Create Key Pair for SSH connection\n+ Launch first EC2 Instance in Public Subnet 16/09/2025 16/09/2025 Cloud Journey - EC2 4 - Virtual Servers EC2 (Part 2):\n+ Practice SSH connection to EC2 (Linux/Windows)\n+ Learn about Security Groups (Inbound/Outbound rules)\n+ Install test Web Server (Apache/Nginx) 17/09/2025 17/09/2025 Cloud Journey - EC2 5 - Granting Permissions with IAM Roles:\n+ Create IAM Role for EC2 (e.g., S3 access)\n+ Attach Role to running EC2 Instance\n+ Verify access permissions from within OS 18/09/2025 18/09/2025 Cloud Journey - IAM Roles 6 - Week 2 Review:\n+ Clean up resources (Terminate Instance) if not in use\n+ Review VPC and Security Group concepts 19/09/2025 19/09/2025 Self-review Week 2 Achievements: Built a complete VPC network with Internet connectivity. Mastered launching, connecting, and managing EC2 Instance lifecycle. Deep understanding of Security Groups - AWS virtual firewalls. Learned to use IAM Roles for secure application permissions instead of hardcoded Access Keys. "
},
{
	"uri": "//localhost:1313/3-blogstranslated/",
	"title": "Translated Blogs",
	"tags": [],
	"description": "",
	"content": " ⚠️ Note: The information below is for reference purposes only, please do not copy verbatim for your report, including this warning.\nHere is a list and introduction of the blogs you have translated.\nBlog 1 - Join AWS at PASS Data Community Summit 2024 AWS participates as a Platinum sponsor at the PASS Data Community Summit 2024. The article highlights AWS\u0026rsquo;s commitment to helping businesses migrate, optimize, and modernize Microsoft SQL Server workloads on the cloud.\nBlog 2 - AWS .NET Distributed Cache Provider for Amazon DynamoDB now Generally Available This article introduces a new library that allows .NET developers to use Amazon DynamoDB as a distributed cache, improving application performance and offloading the primary database.\nBlog 3 - How to generate TLS certificates for a highly available Remote Desktop Gateway Farm A detailed guide on how to generate, import, test, and troubleshoot TLS certificates for a highly available Remote Desktop Gateway (RD Gateway) farm on AWS. The article provides reference architecture and specific steps to ensure security for remote sessions.\n"
},
{
	"uri": "//localhost:1313/3-blogstranslated/3.3-blog3/",
	"title": "How to generate TLS certificates for a highly available Remote Desktop Gateway Farm",
	"tags": [],
	"description": "",
	"content": "Author: Sassan Hajrasooliha\nDate: 22 FEB 2024\nTopic: Amazon EC2, Architecture, Security\u0026hellip;\n(This is a placeholder for the English content. Please refer to the Vietnamese version for the full translated text.)\nIn this post, I will show you how to generate, import, test, and troubleshoot a properly generated Transport Layer Security (TLS) certificate for a Remote Desktop Gateway (RD Gateway) farm.\n"
},
{
	"uri": "//localhost:1313/5-workshop/5.3-integration/",
	"title": "Integrating API Gateway &amp; Authentication",
	"tags": [],
	"description": "",
	"content": "1. Authentication Flow Before coding, let\u0026rsquo;s understand how Frontend communicates with Cognito and API Gateway:\nUser enters User/Pass. Cognito returns JWT Token (ID Token, Access Token). Frontend sends Request with Token in Authorization Header. API Gateway verifies Token. If valid -\u0026gt; Forward to Lambda. 2. Configure AWS Amplify Install aws-amplify library to connect Frontend with AWS services:\nnpm install aws-amplify @aws-amplify/ui-react Configure in src/app/layout.tsx:\n\u0026#39;use client\u0026#39;; import { Amplify } from \u0026#39;aws-amplify\u0026#39;; import config from \u0026#39;@/amplifyconfiguration.json\u0026#39;; Amplify.configure(config); 3. Integrate Amazon Cognito (Authentication) Use Authenticator component to create a secure login/signup flow:\nimport { Authenticator } from \u0026#39;@aws-amplify/ui-react\u0026#39;; export default function LoginPage() { return ( \u0026lt;Authenticator\u0026gt; {({ signOut, user }) =\u0026gt; ( \u0026lt;main\u0026gt; \u0026lt;h1\u0026gt;Welcome, {user?.username}\u0026lt;/h1\u0026gt; \u0026lt;button onClick={signOut}\u0026gt;Sign Out\u0026lt;/button\u0026gt; \u0026lt;/main\u0026gt; )} \u0026lt;/Authenticator\u0026gt; ); } 4. Custom Hook: useAuth (Best Practices) Instead of calling fetchAuthSession everywhere, create a Custom Hook to reuse authentication logic and token retrieval.\n// src/hooks/useAuth.ts import { fetchAuthSession } from \u0026#39;aws-amplify/auth\u0026#39;; import { useState, useEffect } from \u0026#39;react\u0026#39;; export function useAuth() { const [token, setToken] = useState\u0026lt;string | null\u0026gt;(null); useEffect(() =\u0026gt; { const getToken = async () =\u0026gt; { try { const session = await fetchAuthSession(); setToken(session.tokens?.idToken?.toString() || null); } catch (err) { console.error(\u0026#34;Error fetching auth session\u0026#34;, err); } }; getToken(); }, []); return { token }; } 5. API Call with Error Handling Handle errors professionally using try/catch/finally and display feedback to users.\n// src/services/api.ts export const chatWithAI = async (message: string, token: string) =\u0026gt; { try { const response = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/chat`, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Authorization\u0026#39;: `Bearer ${token}` }, body: JSON.stringify({ message }) }); if (!response.ok) { if (response.status === 401) throw new Error(\u0026#34;Session expired\u0026#34;); if (response.status === 429) throw new Error(\u0026#34;Too many requests\u0026#34;); throw new Error(\u0026#34;System error\u0026#34;); } return await response.json(); } catch (error) { console.error(\u0026#34;API Error:\u0026#34;, error); throw error; // Throw error for UI to handle } }; My Experience Never expose API Keys! Once I accidentally committed a .env file containing API Keys to GitHub. AWS sent a warning email immediately. Solution: Always add .env to .gitignore. With Amplify, amplifyconfiguration.json is safe to be public as it only contains Resource IDs (like User Pool ID), not Secret Keys.\nVerification \u0026amp; Testing Test Case 1: Successful Login\nGo to Login page, enter created User/Pass. Click Sign In. Expected Result: Redirect to main page, display \u0026ldquo;Welcome, [Username]\u0026rdquo;. Test Case 2: Token Check\nOpen DevTools (F12) -\u0026gt; Network Tab. Send a Chat message. Find request sent to API Gateway. Check Header: Must have Authorization: Bearer eyJra... line (JWT Token). "
},
{
	"uri": "//localhost:1313/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 3 Objectives: Get familiar with Cloud development environment (Cloud9). Store and host static websites with Amazon S3. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - App Development with AWS Cloud9:\n+ Initialize Cloud9 environment\n+ Get familiar with browser-based IDE interface\n+ Configure integrated AWS CLI in Cloud9 22/09/2025 22/09/2025 Cloud Journey - Cloud9 3 - Storage with Amazon S3 (Part 1):\n+ Create S3 Bucket\n+ Upload/Download Objects (Files, Folders)\n+ Learn about S3 Storage Classes (Standard, IA, Glacier) 23/09/2025 23/09/2025 Cloud Journey - S3 4 - Storage with Amazon S3 (Part 2):\n+ Configure Bucket Policy and Permissions\n+ Enable Versioning for file version management 24/09/2025 24/09/2025 Cloud Journey - S3 5 - Hosting Static Website on S3:\n+ Prepare static web source code (HTML/JS/CSS)\n+ Upload to S3 and enable Static Website Hosting\n+ Configure Public Access for internet visibility 25/09/2025 25/09/2025 Cloud Journey - S3 Static Web 6 - Comprehensive Practice:\n+ Use Cloud9 to code a simple webpage\n+ Use AWS CLI on Cloud9 to sync code to S3 Bucket 26/09/2025 26/09/2025 Workshop Week 3 Achievements: Established a flexible Cloud IDE environment independent of local machine. Clear understanding of Object Storage and data management on S3. Successfully deployed a static website with extremely low cost and high durability. Learned to combine Cloud9 and S3 to optimize development workflow. "
},
{
	"uri": "//localhost:1313/4-eventparticipated/",
	"title": "Events Participated",
	"tags": [],
	"description": "",
	"content": " ⚠️ Note: The information below is for reference purposes only. Please do not copy it verbatim for your report, including this warning.\nIn this section, you should list and describe in detail the events you have participated in during your internship or work experience.\nEach event should be presented in the format Event 1, Event 2, Event 3…, along with the following details:\nEvent name Date and time Location (if applicable) Your role in the event (attendee, event support, speaker, etc.) A brief description of the event’s content and main activities Outcomes or value gained (lessons learned, new skills, contribution to the team/project) This listing helps demonstrate your actual participation as well as the soft skills and experience you have gained from each event. During my internship, I participated in two events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: GenAI-powered App-DB Modernization workshop\nDate \u0026amp; Time: 09:00, August 13, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: GenAI-powered App-DB Modernization workshop\nDate \u0026amp; Time: 09:00, August 13, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\n"
},
{
	"uri": "//localhost:1313/5-workshop/5.4-deployment/",
	"title": "Setting up CI/CD Pipeline with AWS Amplify",
	"tags": [],
	"description": "",
	"content": "1. CI/CD Process We will set up a fully automated process as follows:\nSource: Developer pushes code to GitHub. Build: Amplify automatically detects changes, installs dependencies, and builds Next.js. Deploy: Pushes built code to global Hosting system. Verify: Checks website health (Health Check). 2. Connect Repository Push code to Git Repository (GitHub/GitLab/CodeCommit). In AWS Amplify Console, select Host web app. Connect to the Repository containing Frontend source code. 3. Build Configuration (Build Specification) Amplify uses amplify.yml to define build steps.\nversion: 1 frontend: phases: preBuild: commands: - npm ci build: commands: - npm run build artifacts: baseDirectory: .next files: - \u0026#39;**/*\u0026#39; cache: paths: - node_modules/**/* 4. Environment Variables Management Never hard-code sensitive or environment-specific values (like API URLs) in your code. Use Environment Variables in Amplify.\nGo to App settings \u0026gt; Environment variables. Add variable: Key: NEXT_PUBLIC_API_URL Value: https://xyz.execute-api.us-east-1.amazonaws.com/prod Access in Next.js code via process.env.NEXT_PUBLIC_API_URL. Note: Variables starting with NEXT_PUBLIC_ will be embedded into the Frontend code by Next.js at build time.\n5. Branch Previews (Pull Request Previews) This feature is incredibly useful for team collaboration.\nWhen you create a Pull Request (PR) on GitHub, Amplify automatically creates a temporary Preview environment (with a unique URL). Team Leaders can visit that URL to review new features before Merging into the main branch. After Merging, the Preview environment is automatically deleted. To enable: Go to App settings \u0026gt; Previews \u0026gt; Enable previews.\nMy Experience Build Error on Linux vs Windows My machine uses Windows (case-insensitive), but Amplify runs Linux (case-sensitive). Once I imported Component.tsx but the file was named component.tsx. It ran fine locally, but failed on Amplify with \u0026ldquo;File not found\u0026rdquo;. Lesson: Always name files consistently (PascalCase for Components, camelCase for utils) and double-check when renaming files.\nVerification \u0026amp; Testing Test Case 1: Trigger Build\nEdit a small text line in page.tsx. Commit and Push to GitHub: git push origin main. Go to Amplify Console. Expected Result: See status change to \u0026ldquo;Provisioning\u0026rdquo; -\u0026gt; \u0026ldquo;Building\u0026rdquo; -\u0026gt; \u0026ldquo;Deploying\u0026rdquo;. Test Case 2: Check Logs\nClick on the running build. Open Frontend tab. Expected Result: See green logs (Success) in steps. 2024-05-20T10:00:00.000Z [INFO]: # Executing command: npm run build\r...\r2024-05-20T10:01:00.000Z [INFO]: Compiled successfully "
},
{
	"uri": "//localhost:1313/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 4 Objectives: Get familiar with Amazon Lightsail - the simplified VPS solution. Learn about Containerization (Docker) and deployment on Lightsail. Compare the differences between EC2 and Lightsail. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Amazon Lightsail Basics:\n+ Understand what Lightsail is and its use cases\n+ Launch a Lightsail Instance (WordPress blueprint) 29/09/2025 29/09/2025 Cloud Journey - Lightsail 3 - Lightsail Administration:\n+ Configure Static IP for Lightsail Instance\n+ Connect via browser-based SSH and SSH Client\n+ Manage Firewall on Lightsail console 30/09/2025 30/09/2025 Cloud Journey - Lightsail 4 - Containerization Basics:\n+ Learn about Docker, Containers, and Images\n+ Install Docker on local machine\n+ Write a simple Dockerfile for a Web app 10/01/2025 10/01/2025 Docker Docs 5 - Amazon Lightsail Containers:\n+ Create Lightsail Container Service\n+ Build Docker Image and Push to Lightsail\n+ Deploy container to public internet 10/02/2025 10/02/2025 Cloud Journey - Lightsail Containers 6 - Week 4 Review:\n+ Compare Pros/Cons of Lightsail vs EC2\n+ Clean up Lightsail resources to avoid costs 10/03/2025 10/03/2025 Self-review Week 4 Achievements: Understood when to use Lightsail (fast, bundled) vs EC2 (flexible). Successfully deployed a WordPress website in minutes using Lightsail. Grasped basic concepts of Containers and Docker. Learned how to deploy a containerized application to AWS in the simplest way. "
},
{
	"uri": "//localhost:1313/5-workshop/5.5-advanced-deployment/",
	"title": "Optimization, Security &amp; Monitoring",
	"tags": [],
	"description": "",
	"content": "1. AWS WAF (Web Application Firewall) Protects the application from common web exploits like SQL Injection, XSS, and DDoS.\nRate Limiting Configuration: To prevent application-layer DDoS, set up a rate-based rule:\nRule Type: Rate-based rule. Rate Limit: 100 requests / 5 minutes. Action: Block. Scope: Source IP address. 2. Amazon CloudFront (CDN) Caching: Stores static files at Edge Locations. Invalidation: Automatically invalidates old cache on new deploy. 3. Amazon Route 53 (Custom Domain) Instead of using the long default Amplify domain (...amplifyapp.com), configure a professional custom domain.\nPurchase a domain on Route 53. In Amplify Console \u0026gt; Domain management \u0026gt; Add domain. Amplify automatically creates CNAME records and provisions SSL certificate. 4. Observability: CloudWatch \u0026amp; X-Ray Amazon CloudWatch (Logs \u0026amp; Metrics): Monitor metrics like CPU, Memory, Request count, and Error Rate.\nAWS X-Ray (Distributed Tracing): Visualize the entire journey of a Request: From Frontend -\u0026gt; API Gateway -\u0026gt; Lambda -\u0026gt; Database.\nMy Experience Saving CloudWatch Costs By default, CloudWatch Logs are stored forever (Never Expire). This will eat up your budget after a few months. Solution: Always set Retention Policy to 1 week or 1 month for Dev/Staging environments. Only keep Production logs longer if Audit is required.\nVerification \u0026amp; Testing Test Case 1: Verify WAF (Rate Limiting)\nUse a tool (like JMeter or Python script) to send 200 requests in 1 minute to the website. Expected Result: After the first ~100 requests, subsequent requests receive 403 Forbidden. Test Case 2: Verify Domain \u0026amp; SSL\nAccess https://your-domain.com. Click the padlock icon in the address bar. Expected Result: \u0026ldquo;Connection is secure\u0026rdquo;. Certificate issued by Amazon. "
},
{
	"uri": "//localhost:1313/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 5 Objectives: Understand High Availability and Scalability. Configure EC2 Auto Scaling to automatically scale servers up/down. Comprehensive system monitoring with Amazon CloudWatch. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Prepare for Auto Scaling:\n+ Create AMI (Amazon Machine Image) from a configured EC2 Instance\n+ Create Launch Template from that AMI 10/06/2025 10/06/2025 Cloud Journey - Auto Scaling 3 - Configure Auto Scaling Group (ASG):\n+ Create ASG using Launch Template\n+ Configure Min/Max/Desired capacity\n+ Integrate with Application Load Balancer (ALB) 10/07/2025 10/07/2025 Cloud Journey - Auto Scaling 4 - Amazon CloudWatch (Part 1):\n+ Learn about Metrics and Logs\n+ View CPU, Network metrics of EC2 on CloudWatch Console 10/08/2025 10/08/2025 Cloud Journey - CloudWatch 5 - Amazon CloudWatch (Part 2) \u0026amp; Scaling Policy:\n+ Create CloudWatch Alarm for CPU \u0026gt; 70%\n+ Configure Dynamic Scaling Policy for ASG based on this Alarm\n+ Perform Stress Test to trigger Auto Scaling 10/09/2025 10/09/2025 Cloud Journey - CloudWatch 6 - Week 5 Review:\n+ Observe Scale-out and Scale-in processes\n+ Create CloudWatch Dashboard to aggregate key metrics 10/10/2025 10/10/2025 Self-review Week 5 Achievements: Built a system capable of self-healing and scaling according to actual demand. Understood the role of Load Balancer in traffic distribution. Proficiently used CloudWatch to monitor system \u0026ldquo;health\u0026rdquo;. Successfully executed Stress Test scenario to verify Auto Scaling capabilities. "
},
{
	"uri": "//localhost:1313/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Building Serverless Frontend with Next.js \u0026amp; AWS Amplify Workshop Overview Welcome to the Building Modern Serverless Frontend Workshop. This is not just a coding tutorial, but a journey distilled from real-world experience to build a Production-Ready web application.\nWe will solve the problem: How to create an AI application with a beautiful interface, fast speed, and high security without managing servers?\nTarget Audience:\nFrontend Developers wanting to learn Cloud \u0026amp; DevOps. Students wanting a \u0026ldquo;cool\u0026rdquo; project with the latest tech. Anyone who loves Next.js and AWS. System Architecture Instead of just running code locally, we will build a complete system on AWS:\nData Flow:\nUser accesses website via custom domain (Route 53). Request passes through AWS WAF to filter malicious traffic. CloudFront (CDN) returns static content (HTML/CSS/JS) instantly from Edge Location. When User chats with AI, Request is sent to API Gateway. Cognito authenticates User (ensuring only logged-in users can chat). Lambda processes logic and calls RDS Database to save history. AWS Services Used Category Service Compute AWS Lambda Frontend \u0026amp; Hosting AWS Amplify Hosting Authentication Amazon Cognito API Amazon API Gateway Database Amazon RDS (PostgreSQL) Security AWS WAF CDN \u0026amp; DNS Amazon CloudFront, Amazon Route 53 Monitoring Amazon CloudWatch, AWS X-Ray Estimated Time \u0026amp; Cost Item Details Time 2-3 hours Level Intermediate Cost ~$5-10 (If cleaned up after workshop) Workshop Content The workshop is divided into 7 parts, from basic to advanced:\nPreparation: Setting up VS Code like a Senior Dev. UI Implementation: Coding \u0026ldquo;Mystical\u0026rdquo; interface with TailwindCSS. Integration: Connecting secure APIs with Custom Hooks. CI/CD Pipeline: Automated deployment, no more manual file copying. Advanced Deployment: Optimizing performance and security (WAF, CDN). Backend Architecture: Understanding the backend system (VPC, RDS). Cleanup: Cleaning up to avoid unexpected costs. Advice: Don\u0026rsquo;t just copy-paste code. Read the \u0026ldquo;My Experience\u0026rdquo; section at the end of each article carefully to avoid the mistakes I spent hours debugging!\n"
},
{
	"uri": "//localhost:1313/5-workshop/5.6-backend-architecture/",
	"title": "Reference Backend Architecture (RDS &amp; VPC)",
	"tags": [],
	"description": "",
	"content": "1. VPC Architecture Model The Backend is deployed within a VPC (Virtual Private Cloud) for maximum security:\nPublic Subnet: Contains NAT Gateway (for internal servers to access Internet) and Bastion Host. Private Subnet (App Layer): Contains AWS Lambda. Private Subnet (Data Layer): Contains Amazon RDS (PostgreSQL). 2. Security Group Configuration (Firewall) To ensure \u0026ldquo;Least Privilege\u0026rdquo; principle, we configure strict Security Group rules:\nSecurity Group Inbound Rule Outbound Rule Description SG-Lambda None (or from API Gateway if needed) Allow All to SG-RDS (Port 5432) Lambda is only allowed to call Database. SG-RDS Allow TCP 5432 from SG-Lambda None Database only accepts connections from Lambda, denies all others. 3. VPC Endpoints (PrivateLink) To allow Lambda to access other AWS services (like S3, Secrets Manager, CloudWatch) without going through public Internet (via NAT Gateway), use VPC Endpoints.\nMy Experience Why not put Database in Public Subnet? Beginners often put RDS in Public Subnet for easy connection from local machine. Never do this in Production! Hackers can brute-force your password. Solution: Always put RDS in Private Subnet. If you want to connect from local to debug, use a Bastion Host (Jump Server) or AWS VPN Client.\nVerification \u0026amp; Testing Test Case 1: Verify Lambda -\u0026gt; RDS Connection\nCreate a simple Lambda function executing query SELECT NOW();. Assign Lambda to Private Subnet and SG-Lambda. Run Test on AWS Console. Expected Result: Returns current time from Database. Test Case 2: Verify External Access Block\nTry to connect directly to RDS Endpoint from local machine (via Internet). Expected Result: Connection Timeout (Cannot connect). This proves Database is securely protected inside VPC. "
},
{
	"uri": "//localhost:1313/6-self-evaluation/",
	"title": "Self-Assessment",
	"tags": [],
	"description": "",
	"content": " ⚠️ Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nDuring my internship at [Company/Organization Name] from [start date] to [end date], I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment.\nI participated in [briefly describe the main project or task], through which I improved my skills in [list skills: programming, analysis, reporting, communication, etc.].\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ✅ ☐ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes ☐ ☐ ✅ 6 Progressive mindset Willingness to receive feedback and improve oneself ☐ ✅ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ✅ ☐ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ✅ ☐ ☐ 12 Overall General evaluation of the entire internship period ✅ ☐ ☐ Needs Improvement Strengthen discipline and strictly comply with the rules and regulations of the company or any organization Improve problem-solving thinking Enhance communication skills in both daily interactions and professional contexts, including handling situations effectively "
},
{
	"uri": "//localhost:1313/1-worklog/1.6-week6/",
	"title": "Week 6 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 6 Objectives: Get familiar with NoSQL database (DynamoDB). Learn about Caching to speed up applications (ElastiCache). Enhance AWS CLI skills. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Amazon DynamoDB (Part 1):\n+ Understand differences between SQL (RDS) and NoSQL (DynamoDB)\n+ Create DynamoDB table (Partition Key, Sort Key) 10/13/2025 10/13/2025 Cloud Journey - DynamoDB 3 - Amazon DynamoDB (Part 2):\n+ Practice CRUD (Create, Read, Update, Delete) operations on Console\n+ Learn about Read/Write Capacity Units (RCU/WCU) 10/14/2025 10/14/2025 Cloud Journey - DynamoDB 4 - Amazon ElastiCache:\n+ Learn about In-memory Caching (Redis/Memcached)\n+ Launch ElastiCache Redis Cluster\n+ Test connection from EC2 to Redis 10/15/2025 10/15/2025 Cloud Journey - ElastiCache 5 - Advanced AWS CLI:\n+ Use AWS CLI to interact with DynamoDB (put-item, get-item)\n+ Write simple bash script to backup data from S3 or DynamoDB 10/16/2025 10/16/2025 Cloud Journey - AWS CLI 6 - Week 6 Review:\n+ Review Database knowledge (SQL vs NoSQL vs Cache)\n+ Finalize midterm report (if applicable) 10/17/2025 10/17/2025 Self-review Week 6 Achievements: Clear understanding of NoSQL data models and simple table design in DynamoDB. Learned how to use Caching to offload the main Database. More proficient in using Command Line Interface (CLI) for resource administration. Gained an overview of diverse data storage solutions on AWS. "
},
{
	"uri": "//localhost:1313/5-workshop/5.7-cleanup/",
	"title": "Cleanup Resources",
	"tags": [],
	"description": "",
	"content": "Cleanup Checklist To ensure no costs are incurred after completing the Workshop, delete resources in the following order:\nDelete AWS WAF Web ACL:\nGo to WAF Console -\u0026gt; Web ACLs -\u0026gt; Delete. Note: Must Disassociate from CloudFront before deleting. Delete AWS Amplify App:\nGo to Amplify Console -\u0026gt; Select App -\u0026gt; Actions -\u0026gt; Delete app. This automatically deletes: S3 Bucket (hosting), CloudFront Distribution (if default), Cognito User Pool, and DynamoDB Table (if any). Delete Backend Resources (if manually created):\nRDS Database: Go to RDS Console -\u0026gt; Databases -\u0026gt; Actions -\u0026gt; Delete. (Uncheck \u0026ldquo;Create final snapshot\u0026rdquo; if not needed). Secrets Manager: Schedule deletion for secret (minimum 7 days wait). VPC: Deleting VPC will automatically delete related Subnets, Internet Gateway, Route Tables. (Note: Must delete NAT Gateway and release Elastic IP first). Check Billing Dashboard:\nGo to Billing \u0026amp; Cost Management Dashboard to ensure no services are running in the background. Conclusion Congratulations on successfully completing the \u0026ldquo;Building Modern Serverless Frontend\u0026rdquo; Workshop!\nYou have equipped yourself with comprehensive knowledge from Frontend (Next.js), DevOps (CI/CD), Security (WAF/Cognito) to Backend architecture (RDS/VPC). This is a solid foundation for you to join large-scale real-world projects.\n"
},
{
	"uri": "//localhost:1313/7-feedback/",
	"title": "Sharing and Feedback",
	"tags": [],
	"description": "",
	"content": " ⚠️ Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nHere, you can freely share your personal opinions about your experience participating in the First Cloud Journey program. This will help the FCJ team improve any shortcomings based on the following aspects:\nOverall Evaluation 1. Working Environment\nThe working environment is very friendly and open. FCJ members are always willing to help whenever I encounter difficulties, even outside working hours. The workspace is tidy and comfortable, helping me focus better. However, I think it would be nice to have more social gatherings or team bonding activities to strengthen relationships.\n2. Support from Mentor / Team Admin\nThe mentor provides very detailed guidance, explains clearly when I don’t understand, and always encourages me to ask questions. The admin team supports administrative tasks, provides necessary documents, and creates favorable conditions for me to work effectively. I especially appreciate that the mentor allows me to try and solve problems myself instead of just giving the answer.\n3. Relevance of Work to Academic Major\nThe tasks I was assigned align well with the knowledge I learned at university, while also introducing me to new areas I had never encountered before. This allowed me to both strengthen my foundational knowledge and gain practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as using project management tools, teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive: everyone respects each other, works seriously but still keeps things enjoyable. When there are urgent projects, everyone works together and supports one another regardless of their position. This made me feel like a real part of the team, even as an intern.\n6. Internship Policies / Benefits\nThe company provides an internship allowance and offers flexible working hours when needed. In addition, having the opportunity to join internal training sessions is a big plus.\nAdditional Questions What did you find most satisfying during your internship? What do you think the company should improve for future interns? If recommending to a friend, would you suggest they intern here? Why or why not? Suggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience? Would you like to continue this program in the future? Any other comments (free sharing): "
},
{
	"uri": "//localhost:1313/1-worklog/1.7-week7/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 7 Objectives: Advanced AWS Networking knowledge. Optimize content delivery with CDN (CloudFront). Edge Security for web applications. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Networking Workshop (Part 1):\n+ Learn about VPC Peering (connecting 2 VPCs)\n+ Practice creating 2 VPCs and establishing Peering Connection\n+ Configure Route Tables for connectivity 10/20/2025 10/20/2025 Cloud Journey - Networking 3 - Networking Workshop (Part 2):\n+ Learn about Site-to-Site VPN (theory)\n+ Simulate VPN connection (if possible) or learn Transit Gateway\n+ VPC Endpoints (PrivateLink) for internal AWS service access 10/21/2025 10/21/2025 Cloud Journey - Networking 4 - Amazon CloudFront (Part 1):\n+ Learn about CDN and Edge Locations\n+ Create CloudFront Distribution for S3 Bucket (from Week 3)\n+ Configure OAI (Origin Access Identity) to secure S3 10/22/2025 10/22/2025 Cloud Journey - CloudFront 5 - Amazon CloudFront (Part 2) \u0026amp; WAF:\n+ Configure Custom Domain and SSL Certificate (ACM) for CloudFront\n+ Learn about AWS WAF (Web Application Firewall)\n+ Create simple WAF ACL (IP block/Geo-block) attached to CloudFront 10/23/2025 10/23/2025 Cloud Journey - CloudFront 6 - Week 7 Review:\n+ Compare website access speed via CDN vs direct S3\n+ Review all Networking and Content Delivery knowledge 10/24/2025 10/24/2025 Self-review Week 7 Achievements: Deep understanding of AWS network architecture and VPC interconnection. Successfully deployed CDN to accelerate page load speed for global users. Learned how to secure origin content (S3) from direct access. Grasped how to protect applications from basic web attacks using WAF. "
},
{
	"uri": "//localhost:1313/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 8 Objectives: Begin System Optimization phase. Automate Operations with AWS Lambda and Systems Manager. Basic Infrastructure as Code (IaC). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Automation with AWS Lambda:\n+ Learn about Serverless and Lambda functions\n+ Write Python (Boto3) function to auto Start/Stop EC2 instances on schedule\n+ Configure EventBridge (CloudWatch Events) to trigger Lambda 10/27/2025 10/27/2025 Cloud Journey - Optimize 3 - Advanced Observability:\n+ Create custom Dashboards on CloudWatch\n+ Integrate CloudWatch with SNS for Email/SMS alerts\n+ Learn about Grafana (if covered) 10/28/2025 10/28/2025 Cloud Journey - Optimize 4 - AWS Systems Manager (SSM):\n+ Install SSM Agent on EC2\n+ Use Session Manager to remote into EC2 without opening port 22 (SSH)\n+ Use Run Command to execute commands on multiple servers simultaneously 10/29/2025 10/29/2025 Cloud Journey - Optimize 5 - Resource Management \u0026amp; IaC:\n+ Use Tagging Strategy for cost and resource management\n+ Learn basic AWS CloudFormation\n+ Create a simple Stack (e.g., create S3 bucket using YAML/JSON code) 10/30/2025 10/30/2025 Cloud Journey - Optimize 6 - Week 8 Review:\n+ Review implemented automation solutions\n+ Evaluate effectiveness of SSM vs traditional SSH 10/31/2025 10/31/2025 Self-review Week 8 Achievements: Started adopting \u0026ldquo;Automate everything\u0026rdquo; mindset in system operations. Wrote practical Lambda function to save costs (stopping servers off-hours). Managed servers more securely and professionally with Systems Manager (no Bastion Host needed). Understood Infrastructure as Code (IaC) concepts preparing for larger deployments. "
},
{
	"uri": "//localhost:1313/1-worklog/1.9-week9/",
	"title": "Week 9 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 9 Objectives: Begin Application Modernization phase. Understand Serverless architecture. Build first API with API Gateway and Lambda. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Serverless Overview:\n+ Learn Serverless concepts and benefits\n+ Analyze Monolith vs Microservices architecture\n+ Intro to the trio: Lambda, API Gateway, DynamoDB 11/03/2025 11/03/2025 Cloud Journey - Modernize 3 - AWS Lambda \u0026amp; DynamoDB:\n+ Write Lambda function (Node.js/Python) to interact with DynamoDB (CRUD)\n+ Configure IAM Role allowing Lambda access to DynamoDB 11/04/2025 11/04/2025 Cloud Journey - Serverless 4 - Amazon API Gateway:\n+ Create REST API with API Gateway\n+ Integrate API Gateway with Lambda function\n+ Deploy API and test with Postman 11/05/2025 11/05/2025 Cloud Journey - Serverless 5 - Building Serverless Backend:\n+ Finalize APIs: Create, Read, Update, Delete Item\n+ Handle errors and response mapping in Lambda 11/06/2025 11/06/2025 Cloud Journey - Serverless 6 - Week 9 Review:\n+ Review built Serverless architecture\n+ Compare cost and performance vs traditional EC2 11/07/2025 11/07/2025 Self-review Week 9 Achievements: Clear understanding of Serverless design mindset (no server management). Successfully built a complete Backend system (API + Compute + Database) without launching any servers. Mastered integration between core services: API Gateway -\u0026gt; Lambda -\u0026gt; DynamoDB. "
},
{
	"uri": "//localhost:1313/1-worklog/1.10-week10/",
	"title": "Week 10 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 10 Objectives: Complete Serverless Application (Frontend + Backend). Secure application with Amazon Cognito. Asynchronous processing with SQS/SNS. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Serverless Frontend:\n+ Build static website (HTML/JS) calling API Gateway\n+ Host website on S3 with SSL (HTTPS)\n+ Handle CORS on API Gateway 11/10/2025 11/10/2025 Cloud Journey - Serverless 3 - Authentication with Amazon Cognito:\n+ Create User Pool to manage users\n+ Integrate Cognito into Frontend (Sign up/Sign in)\n+ Protect API Gateway with Cognito Authorizer 11/11/2025 11/11/2025 Cloud Journey - Cognito 4 - Messaging \u0026amp; Eventing:\n+ Learn about Decoupling architecture\n+ Create SQS Queue for pending orders\n+ Create SNS Topic for email notifications 11/12/2025 11/12/2025 Cloud Journey - SQS/SNS 5 - System Integration:\n+ Modify Lambda to push messages to SQS instead of processing immediately\n+ Write Lambda Trigger to process messages from SQS\n+ Send SNS notification upon completion 11/13/2025 11/13/2025 Cloud Journey - Serverless 6 - Week 10 Review:\n+ Test full flow: Frontend -\u0026gt; API -\u0026gt; Lambda -\u0026gt; SQS -\u0026gt; Lambda -\u0026gt; DB -\u0026gt; SNS\n+ Evaluate latency and load capacity 11/14/2025 11/14/2025 Self-review Week 10 Achievements: Successfully built a complete Fullstack Serverless application. Learned professional API security and user management with Cognito. Understood and deployed Asynchronous architecture to prevent system bottlenecks. "
},
{
	"uri": "//localhost:1313/1-worklog/1.11-week11/",
	"title": "Week 11 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 11 Objectives: Automate deployment process (CI/CD) for Serverless applications. Advanced Monitoring \u0026amp; Tracing. Introduction to GraphQL (AppSync) - modern API technology. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - CI/CD with AWS CodePipeline:\n+ Create Repository on AWS CodeCommit (or GitHub)\n+ Create Build Project with AWS CodeBuild (buildspec.yml)\n+ Set up Pipeline to auto-deploy on new code commit 11/17/2025 11/17/2025 Cloud Journey - CI/CD 3 - Monitoring with CloudWatch \u0026amp; X-Ray:\n+ Enable X-Ray tracing for Lambda and API Gateway\n+ Analyze Service Map to find bottlenecks\n+ View detailed logs on CloudWatch Logs Insights 11/18/2025 11/18/2025 Cloud Journey - Monitoring 4 - Intro to AWS AppSync (GraphQL):\n+ Understand differences between REST API and GraphQL\n+ Create simple AppSync API connected to DynamoDB\n+ Test queries and mutations on Console 11/19/2025 11/19/2025 Cloud Journey - AppSync 5 - Advanced Practice (Optional):\n+ Experiment with AWS SAM (Serverless Application Model) to define infrastructure as code\n+ Deploy application using sam deploy command 11/20/2025 11/20/2025 Cloud Journey - SAM 6 - Week 11 Review:\n+ Review the entire Application Modernization process\n+ Prepare materials and metrics for final report 11/21/2025 11/21/2025 Self-review Week 11 Achievements: Established automated CI/CD pipeline, reducing human error during deployment. Capable of debugging and optimizing complex Serverless application performance using X-Ray. Exposed to modern GraphQL technology via AWS AppSync. Ready for summarizing and reporting internship results. "
},
{
	"uri": "//localhost:1313/1-worklog/1.12-week12/",
	"title": "Week 12 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 12 Objectives: Review all work done during the internship. Finalize Internship Report. Prepare Slides and Script for Final Defense presentation. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Consolidate Worklogs:\n+ Review Worklogs from Week 1 to Week 11\n+ Update missing results or illustrations\n+ Sync content to the report site (Hugo Site) 11/24/2025 11/24/2025 Self-review 3 - Write Final Report:\n+ Complete chapters: Company Intro, Theoretical Basis, Internship Content, Results\n+ Write Conclusion and Recommendations\n+ Format document according to university standards 11/25/2025 11/25/2025 University Template 4 - Prepare Presentation Slides:\n+ Summarize key projects (Serverless App, Auto Scaling System)\n+ Design visual slides, focusing on Demo and Results\n+ Prepare live demo script (if applicable) 11/26/2025 11/26/2025 Self-review 5 - Practice \u0026amp; Rehearsal:\n+ Rehearse presentation with Mentor or peers\n+ Anticipate Q\u0026amp;A questions and prepare answers\n+ Final check of Demo system 11/27/2025 11/27/2025 Self-review 6 - Cleanup \u0026amp; Handover:\n+ Delete unused AWS resources to avoid post-internship costs\n+ Hand over code and documentation to Mentor (if required)\n+ Send thank you notes to company and team 11/28/2025 11/28/2025 Self-review Week 12 Achievements: Completed 100% of Internship Report and Report Website. Fully prepared for the final defense. Ensured no residual resources left on AWS Account. Concluded the internship professionally. "
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]